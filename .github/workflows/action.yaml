name: MLOps Pipeline

permissions:
  id-token: write
  contents: write

env:
  team_name: "MLOps Rocks!"
  GIT_USER_NAME: github-actions[bot]
  GIT_USER_EMAIL: github-actions[bot]@users.noreply.github.com

on:
  push:
    branches:
      - main
  workflow_dispatch:

jobs:
  mlops:
    name: Testing the pipeline
    runs-on: ["self-hosted", "Linux", "X64", "k8s"]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Capture start time
        run: echo "START_TIME=$(date +%s)" >> $GITHUB_ENV

      - name: Ensure Python + DVC + Nextflow
        run: |
          python3 -m venv .venv
          source .venv/bin/activate
          pip install --upgrade pip
          pip install dvc[s3]

          apt-get update && apt-get install -y openjdk-17-jre
          curl -s https://get.nextflow.io | bash
          chmod +x nextflow
          mv nextflow /usr/local/bin/

      - name: Create MinIO bucket (if missing)
        run: |
          curl -sLO https://dl.min.io/client/mc/release/linux-amd64/mc
          chmod +x mc
          mv mc /usr/local/bin/

          mc alias set local "$MINIO_ENDPOINT" "$MINIO_ACCESS_KEY" "$MINIO_SECRET_KEY"
          mc ls local | grep -q mlops-dvc-storage || mc mb local/mlops-dvc-storage
          echo "✅ Bucket ready"

      - name: Configure DVC dynamically
        run: |
          source .venv/bin/activate
          dvc init --no-scm 
          dvc remote add -d minio-store s3://mlops-dvc-storage/
          dvc remote modify minio-store endpointurl $MINIO_ENDPOINT
          dvc remote modify minio-store access_key_id $MINIO_ACCESS_KEY
          dvc remote modify minio-store secret_access_key $MINIO_SECRET_KEY
          dvc remote modify minio-store region eu-central-1
          dvc remote modify minio-store use_ssl false
      
      - name: Try a dvc push now
        run: |
          source .venv/bin/activate
          dvc push
          
      - name: Inject Kaggle API token
        run: |
          mkdir -p ~/.kaggle
          echo "${KAGGLE_TOKEN_JSON}" > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json
        env:
          KAGGLE_TOKEN_JSON: ${{ secrets.KAGGLE_TOKEN_JSON }}

      - name: Configure and run DVC pipeline
        run: |
          source .venv/bin/activate
          rm -rf .nextflow* work/ outputs/
          dvc repro
          echo "✅ DVC pipeline ran successfully."

      - name: Push tracked data to MinIO
        if: success()
        run: |
          source .venv/bin/activate
          dvc push
      - name: Check if there are DVC-tracked changes
        id: check_changes
        run: |
          source .venv/bin/activate
          if git diff --exit-code dvc.lock; then
            echo "changed=false" >> $GITHUB_OUTPUT
          else
            echo "changed=true" >> $GITHUB_OUTPUT
          fi

      - name: Commit and tag if DVC.lock changed
        if: steps.check_changes.outputs.changed == 'true'
        run: |
          git config user.name "$GIT_USER_NAME"
          git config user.email "$GIT_USER_EMAIL"
          git add dvc.lock
          git commit -m "Update data artifacts [skip ci]"
          TAG="data-v$(date +'%Y%m%d%H%M%S')"
          git tag "$TAG"
          git push origin main --tags

      - name: Generate and upload metadata
        if: success()
        run: |
          TIMESTAMP=$(date +'%Y-%m-%dT%H:%M:%S')
          GIT_HASH=$(git rev-parse HEAD)
          VERSION_TAG=$(git describe --tags --abbrev=0 || echo 'untagged')
          PIPELINE_NAME="${{ github.workflow }}"
          END_TIME=$(date +%s)
          RUN_DURATION=$(( END_TIME - START_TIME ))

          cat <<EOF > metadata.json
          {
            "timestamp": "$TIMESTAMP",
            "git_commit": "$GIT_HASH",
            "dataset_version": "$VERSION_TAG",
            "pipeline_name": "$PIPELINE_NAME",
            "run_duration_seconds": $RUN_DURATION,
            "team_name": "${{ env.team_name }}"
          }
          EOF

          mc alias set local "$MINIO_ENDPOINT" "$MINIO_ACCESS_KEY" "$MINIO_SECRET_KEY"
          mc cp metadata.json localminio/metadata-bucket/metadata-$TIMESTAMP.json

      - name: Upload Nextflow artifacts to MinIO
        if: success()
        run: |
          mc alias set local "$MINIO_ENDPOINT" "$MINIO_ACCESS_KEY" "$MINIO_SECRET_KEY"
          mc mb --ignore-existing localminio/dvc-bucket
          for f in pipeline_report.html pipeline_timeline.html pipeline_trace.txt; do
            if [[ -f "$f" ]]; then
              mc cp "$f" localminio/dvc-bucket/artifacts/"${f%.*}-$(date +'%Y%m%d%H%M%S').${f##*.}"
            fi
          done

      - name: Index metadata into Elasticsearch
        if: success()
        run: |
          curl -XPOST "${ES_DEMO_ES_INTERNAL_HTTP_SERVICE}:9200/mlops-metadata/_doc" \
            -H 'Content-Type: application/json' \
            --data-binary @metadata.json

    #   - name: Send success email
    #     if: success()
    #     uses: dawidd6/action-send-mail@v3
    #     with:
    #       server_address: ${{ secrets.EMAIL_SERVER }}
    #       server_port: ${{ secrets.EMAIL_PORT }}
    #       username: ${{ secrets.EMAIL_USERNAME }}
    #       password: ${{ secrets.EMAIL_PASSWORD }}
    #       subject: "✅ MLOps Pipeline Success - Data Updated"
    #       body: |
    #         The MLOps pipeline completed successfully.
    #         Latest dataset version: ${{ env.VERSION_TAG }}
    #         Commit: ${{ env.GIT_HASH }}
    #       to: ${{ secrets.EMAIL_TO }}
    #       from: ${{ secrets.EMAIL_USERNAME }}

    #   - name: Send failure email
    #     if: failure()
    #     uses: dawidd6/action-send-mail@v3
    #     with:
    #       server_address: ${{ secrets.EMAIL_SERVER }}
    #       server_port: ${{ secrets.EMAIL_PORT }}
    #       username: ${{ secrets.EMAIL_USERNAME }}
    #       password: ${{ secrets.EMAIL_PASSWORD }}
    #       subject: "❌ MLOps Pipeline Failed!"
    #       body: |
    #         The MLOps pipeline FAILED. Check the GitHub Actions logs.
    #       to: ${{ secrets.EMAIL_TO }}
    #       from: ${{ secrets.EMAIL_USERNAME }}

    #   - name: Import Kibana Dashboard
    #     run: |
    #       curl -XPOST "${{ secrets.ELK_ENDPOINT }}/api/saved_objects/_import?overwrite=true" \
    #       -H "kbn-xsrf: true" \
    #       -F "file=@cluster-setup/elk/mlops-pipeline-dashboard.ndjson"
    #       curl -XPOST "${{ secrets.ELK_ENDPOINT }}/api/saved_objects/_import?overwrite=true" \
    #       -H "kbn-xsrf: true" \
    #       -F "file=@infra/kibana/mlops-summary-dashboard.ndjson"

    #   - name: Parse pipeline trace and send summary to ELK
    #     run: |
    #       START_TIME=$(head -2 pipeline_trace.txt | tail -1 | awk '{print $3}')
    #       END_TIME=$(tail -2 pipeline_trace.txt | head -1 | awk '{print $4}')
    #       TOTAL_PROCESSES=$(cat pipeline_trace.txt | grep -c "process")
    #       TIMESTAMP=$(date +'%Y-%m-%dT%H:%M:%S')
    #       GIT_HASH=$(git rev-parse HEAD)
    #       VERSION_TAG=$(git describe --tags --abbrev=0 || echo 'untagged')
    #       PIPELINE_NAME=${{ github.workflow }}
    #       RUN_DURATION=$(( $END_TIME - $START_TIME ))

    #       cat <<EOF > pipeline_summary.json
    #       {
    #         "timestamp": "$TIMESTAMP",
    #         "git_commit": "$GIT_HASH",
    #         "dataset_version": "$VERSION_TAG",
    #         "pipeline_name": "$PIPELINE_NAME",
    #         "run_duration_seconds": $RUN_DURATION,
    #         "total_processes": $TOTAL_PROCESSES
    #       }
    #       EOF

    #       curl -XPOST "${{ secrets.ELK_ENDPOINT }}/mlops-summary/_doc" \
    #         -H "kbn-xsrf: true" \
    #         -H "Content-Type: application/json" \
    #         --data-binary @pipeline_summary.json


