name: MLOps Pipeline

permissions:
  id-token: write
  contents: read

env:
  team_name: "MLOps Rocks!"

on:
  push:
    branches:
      - main
  workflow_dispatch:

jobs:
  mlops:
    name: Testing the pipeline
    runs-on: ["self-hosted", "Linux", "X64", "k8s"]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Ensure Python + DVC
        run: |
          python3 -m venv .venv
          source .venv/bin/activate
          pip install --upgrade pip
          pip install dvc[s3] minio
        shell: bash
      - name: Create MinIO bucket (if missing)
        run: |
          source .venv/bin/activate
          python3 - <<EOF
          from minio import Minio
          import os

          client = Minio(
              os.environ["MINIO_ENDPOINT"].replace("http://", "").replace("https://", ""),
              access_key=os.environ["MINIO_ACCESS_KEY"],
              secret_key=os.environ["MINIO_SECRET_KEY"],
              region="", #This is apparently the solution
              secure=False
          )
    
          bucket = "mlops-dvc-storage"
          if not client.bucket_exists(bucket):
              client.make_bucket(bucket)
              print(f"✅ Created bucket: {bucket}")
          else:
              print(f"✅ Bucket already exists: {bucket}")
          EOF

      - name: Configure DVC dynamically
        run: |
          dvc remote add -d minio-store s3://mlops-dvc-storage/
          dvc remote modify minio-store endpointurl $MINIO_ENDPOINT
          dvc remote modify minio-store access_key_id $MINIO_ACCESS_KEY
          dvc remote modify minio-store secret_access_key $MINIO_SECRET_KEY
          dvc remote modify minio-store region eu-central-1
          dvc remote modify minio-store use_ssl false
      
      - name: Try a dvc push now
        run: |
          source .venv/bin/activate
          dvc push
      # - name: Print system info
      #   run: uname -a

      # - name: Show disk space
      #   run: df -h

      # - name: Test networking
      #   run: curl -I https://google.com || true

      # - name: Success mark
      #   run: echo "✅ Runner is working correctly"

    # runs-on: ubuntu-latest
    # steps:
    #   - name: Record start time
    #     run: echo "START_TIME=$(date +%s)" >> $GITHUB_ENV

    #   - name: Checkout repository
    #     uses: actions/checkout@v4

    #   - name: Set up Python
    #     uses: actions/setup-python@v5
    #     with:
    #       python-version: '3.10'

    #   - name: Install MinIO client (mc)
    #     run: |
    #       curl -O https://dl.min.io/client/mc/release/linux-amd64/mc
    #       chmod +x mc
    #       sudo mv mc /usr/local/bin/

    #   - name: Ensure that buckets exist
    #     run: |
    #       mc alias set localminio ${{ secrets.MINIO_ENDPOINT }} ${{ secrets.MINIO_ACCESS_KEY }} ${{ secrets.MINIO_SECRET_KEY }}
    #       mc mb --ignore-existing localminio/dvc-bucket
    #       mc mb --ignore-existing localminio/metadata-bucket
  
    #   - name: Install DVC and Nextflow
    #     run: |
    #       pip install dvc[s3]
    #       curl -s https://get.nextflow.io | bash
    #       sudo mv nextflow /usr/local/bin/

    #   - name: Configure DVC remote (MinIO)
    #     run: |
    #       dvc remote add -f -d minioremote s3://dvc-bucket
    #       dvc remote modify minioremote endpointurl ${{ secrets.MINIO_ENDPOINT }}
    #       dvc remote modify minioremote access_key_id ${{ secrets.MINIO_ACCESS_KEY }}
    #       dvc remote modify minioremote secret_access_key ${{ secrets.MINIO_SECRET_KEY }}

    #   - name: DVC pull
    #     run: |
    #       dvc pull -j 8

    #   - name: DVC repro (run Nextflow pipeline)
    #     run: |
    #       dvc repro
      
    #   - name: Record end time
    #     run: echo "END_TIME=$(date +%s)" >> $GITHUB_ENV

    #   - name: DVC push outputs
    #     run: |
    #       dvc push -j 8

    #   - name: Check if there are changes
    #     id: changes
    #     run: |
    #       git diff --exit-code || echo "changes=true" >> $GITHUB_ENV

    #   - name: Commit and tag if changes
    #     if: ${{ env.changes }} == 'true'
    #     run: |
    #       git config user.name "github-actions[bot]"
    #       git config user.email "github-actions[bot]@users.noreply.github.com"
    #       git add cicd-demo/dvc-store/
    #       git commit -m "Update data artifacts [skip ci]" || echo "No changes to commit"
    #       git tag "data-v$(date +'%Y%m%d%H%M%S')"
    #       git push origin main --tags

    #   - name: Generate and upload metadata
    #     run: |
    #       TIMESTAMP=$(date +'%Y-%m-%dT%H:%M:%S')
    #       GIT_HASH=$(git rev-parse HEAD)
    #       VERSION_TAG=$(git describe --tags --abbrev=0 || echo 'untagged')
    #       PIPELINE_NAME=${{ github.workflow }}
    #       RUN_DURATION=$(( $END_TIME - $START_TIME ))
    #       echo "Pipeline duration: ${RUN_DURATION} seconds"
    #       cat <<EOF > metadata.json
    #       {
    #         "timestamp": "$TIMESTAMP",
    #         "git_commit": "$GIT_HASH",
    #         "dataset_version": "$VERSION_TAG",
    #         "pipeline_name": "$PIPELINE_NAME",
    #         "run_duration_seconds": $RUN_DURATION,
    #         "team_name": ${{ env.team_name }}
    #       }
    #       EOF
    #       mc alias set localminio ${{ secrets.MINIO_ENDPOINT }} ${{ secrets.MINIO_ACCESS_KEY }} ${{ secrets.MINIO_SECRET_KEY }}
    #       mc cp metadata.json localminio/metadata-bucket/metadata-$TIMESTAMP.json
      
    #   - name: Upload Nextflow artifacts to MinIO
    #     run: |
    #       mc alias set localminio ${{ secrets.MINIO_ENDPOINT }} ${{ secrets.MINIO_ACCESS_KEY }} ${{ secrets.MINIO_SECRET_KEY }}
    #       mc mb --ignore-existing localminio/dvc-bucket
    #       mc cp pipeline_report.html localminio/dvc-bucket/artifacts/pipeline_report-$(date +'%Y%m%d%H%M%S').html
    #       mc cp pipeline_timeline.html localminio/dvc-bucket/artifacts/pipeline_timeline-$(date +'%Y%m%d%H%M%S').html
    #       mc cp pipeline_trace.txt localminio/dvc-bucket/artifacts/pipeline_trace-$(date +'%Y%m%d%H%M%S').txt

          
    #   - name: Index metadata into Elasticsearch
    #     if: success()
    #     run: |
    #       curl -XPOST "${{ secrets.ELK_ENDPOINT }}/mlops-metadata/_doc" \
    #         -H 'Content-Type: application/json' \
    #         --data-binary @metadata.json

    #   - name: Send success email
    #     if: success()
    #     uses: dawidd6/action-send-mail@v3
    #     with:
    #       server_address: ${{ secrets.EMAIL_SERVER }}
    #       server_port: ${{ secrets.EMAIL_PORT }}
    #       username: ${{ secrets.EMAIL_USERNAME }}
    #       password: ${{ secrets.EMAIL_PASSWORD }}
    #       subject: "✅ MLOps Pipeline Success - Data Updated"
    #       body: |
    #         The MLOps pipeline completed successfully.
    #         Latest dataset version: ${{ env.VERSION_TAG }}
    #         Commit: ${{ env.GIT_HASH }}
    #       to: ${{ secrets.EMAIL_TO }}
    #       from: ${{ secrets.EMAIL_USERNAME }}

    #   - name: Send failure email
    #     if: failure()
    #     uses: dawidd6/action-send-mail@v3
    #     with:
    #       server_address: ${{ secrets.EMAIL_SERVER }}
    #       server_port: ${{ secrets.EMAIL_PORT }}
    #       username: ${{ secrets.EMAIL_USERNAME }}
    #       password: ${{ secrets.EMAIL_PASSWORD }}
    #       subject: "❌ MLOps Pipeline Failed!"
    #       body: |
    #         The MLOps pipeline FAILED. Check the GitHub Actions logs.
    #       to: ${{ secrets.EMAIL_TO }}
    #       from: ${{ secrets.EMAIL_USERNAME }}

    #   - name: Import Kibana Dashboard
    #     run: |
    #       curl -XPOST "${{ secrets.ELK_ENDPOINT }}/api/saved_objects/_import?overwrite=true" \
    #       -H "kbn-xsrf: true" \
    #       -F "file=@cluster-setup/elk/mlops-pipeline-dashboard.ndjson"
    #       curl -XPOST "${{ secrets.ELK_ENDPOINT }}/api/saved_objects/_import?overwrite=true" \
    #       -H "kbn-xsrf: true" \
    #       -F "file=@infra/kibana/mlops-summary-dashboard.ndjson"

    #   - name: Parse pipeline trace and send summary to ELK
    #     run: |
    #       START_TIME=$(head -2 pipeline_trace.txt | tail -1 | awk '{print $3}')
    #       END_TIME=$(tail -2 pipeline_trace.txt | head -1 | awk '{print $4}')
    #       TOTAL_PROCESSES=$(cat pipeline_trace.txt | grep -c "process")
    #       TIMESTAMP=$(date +'%Y-%m-%dT%H:%M:%S')
    #       GIT_HASH=$(git rev-parse HEAD)
    #       VERSION_TAG=$(git describe --tags --abbrev=0 || echo 'untagged')
    #       PIPELINE_NAME=${{ github.workflow }}
    #       RUN_DURATION=$(( $END_TIME - $START_TIME ))

    #       cat <<EOF > pipeline_summary.json
    #       {
    #         "timestamp": "$TIMESTAMP",
    #         "git_commit": "$GIT_HASH",
    #         "dataset_version": "$VERSION_TAG",
    #         "pipeline_name": "$PIPELINE_NAME",
    #         "run_duration_seconds": $RUN_DURATION,
    #         "total_processes": $TOTAL_PROCESSES
    #       }
    #       EOF

    #       curl -XPOST "${{ secrets.ELK_ENDPOINT }}/mlops-summary/_doc" \
    #         -H "kbn-xsrf: true" \
    #         -H "Content-Type: application/json" \
    #         --data-binary @pipeline_summary.json


